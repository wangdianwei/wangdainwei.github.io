<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />

<title>Kai-Fu Yang</title>

</head>
<body>

<!-- Project
<div class="menu"> <a href="#home">Home</a> 
<a href="#publications">Publications</a> 
<a href="#services">Services</a> 
<a href="#awards">Awards</a>  
</div>
 -->
 
<a id="home" class="anchor"></a>
<div id="container"> 
<div class="container"> 
<!--
<div id="toptitle">
<h1>Kai-Fu Yang</h1>
</div>
 -->

<table class="imgtable"><tr><td>
<a href="./"><img src="./pics/1.png" alt="" height="220px" /></a>&nbsp;</td>
<td align="left"><p><font size="5">Dian-Wei Wang (王殿伟)</font> <br />
Associate  Professor (副教授) <br />
Research Direction <br />
UAV Intelligent Situation Awareness, Fire Smoke Intelligent Monitoring and Early Warning, Low-Iight Image Enhancement Processing <br />
无人机智能态势感知、火灾烟雾智能监测与预警、低光照图像增强处理<br />
<br />
Teaching Direction <br />
Computer Vision and Artificial Intelligence，Digital Image Processing <br />
计算机视觉与人工智能、数字图像处理
<br />	
<a href="https://www.neuro.uestc.edu.cn/vccl/home.html">Center for Visual Cognition and Brain-Inspired Computation</a><br />
Xi’an University of Posts & Telecommunications(XUPT)<br />
No.618, West Chang'an Street, Chang'an District, Xi'an 710121, China. <br />
<br />
Email:wangdianwei@126.com <br />
[<a class="p" href="https://scholar.google.com/citations?user=i0VkF0EAAAAJ&hl=en" target="_blank">Google Scholar</a>]</p>
</td></tr></table>

<h2>About Me</h2>
<p>I am an associate research professor at the MOE Key Lab for Neuroinformation, School of Life Science and Technology, University of Electronic Science and Technology of China (UESTC). I received my Ph.D. degree in Biomedical Engineering from UESTC in 2016 under the supervision of Prof. Yong-Jie Li. From August 2019 to August 2020, I was a visiting scholar at the Computer Vision Lab, Department of Information Technology and Electrical Engineering, ETH Zurich, Switzerland.</p>

<h2>Research Interests</h2>
<p>I conduct interdisciplinary research at the intersection of visual cognition and computer vision. My research aims to explore the underlying computational theory of visual cognition and develop bio-inspired methods for computer vision applications. Through a combination of computational modeling and behavioral experiments, such as eye-tracking, we investigate the computational basis of many aspects of vision, such as visual perception, visual attention, and object recognition. In addition, we also try to explore new methods for medical data analysis.</p>

<!--<h2>News</h2>-->
<!--<ul>-->
<!--<li> XXXX.</li>-->
<!--</ul>-->

<!-- Project -->
<a id="projects" class="anchor"></a>
<h2>Projects and Publications</h2>
	
<!--<h3>(1) Cognitive-Driven Active Vision</h3> -->
<!--To build the computational theory of visual cognition, focusing on the interaction of the cognition system and visual scenes, i.e., the active vision. -->
<!--<hr> -->
	
<h3>(1) Bio-inspired Computer Vision</h3>
<!--To explore the computational models of visual perception and develop bio-inspired methods for computer vision applications.-->
<hr>
	
<table class="imgtable">
		
<!--Adaptation-->
<tr>
<td><img class="proj_thumb" src="./pics/VisEnh.png" alt="" height="120px"/>&nbsp;</td>
<td>
<p class="pub_title">Visual Adaptation and Image Enhancement  </p>
<font size="2.5">
<li><b>KF Yang</b>, C Cheng, SX Zhao, HM Yan, XS Zhang, YJ Li. Learning to Adapt to Light. <b>IJCV</b>, 2023. [<a class="p" href="https://github.com/kaifuyang/LA-Net" target="_blank">Codes</a>]</li>
<li>XS Zhang, YB Yu, <b>KF Yang</b>, YJ Li. A fish retina-inspired single image dehazing method. <b>IEEE TCSVT</b>, 2022.</li>
<li><b>KF Yang</b>, XS Zhang, YJ Li. A Biological Vision Inspired Framework for Image Enhancement in Poor Visibility Conditions. <b>IEEE TIP</b>, 2020. [<a class="p" href="https://github.com/kaifuyang/Visual-Adaptation" target="_blank">Codes</a>]</li>
<li>XS Zhang, <b>KF Yang</b>, J Zhou, YJ Li. Retina inspired tone mapping method for high dynamic range images. <b>Optics Express</b>, 2020.</li>	
<li><b>KF Yang</b>, H Li, HL Kuang, CY Li, YJ Li. An Adaptive Method for Image Dynamic Range Adjustment. <b>IEEE TCSVT</b>, 2019. [<a class="p" href="https://github.com/kaifuyang/Visual-Adaptation" target="_blank">Codes</a>]</li>
</font>
</p> </td>
</tr>

		
<!-- Grey Pixel-->
<tr>
<td><img class="proj_thumb" src="./pics/CC.png" alt="" height="120px"/>&nbsp;</td>
<td>
<p class="pub_title">Gray Pixel and Color Constancy</p>
<font size="2.5">
<li><b>KF Yang</b>, SB Gao, YJ Li. Efficient Illuminant Estimation for Color Constancy Using Grey Pixels. <b>CVPR</b>, 2015. [<a class="p" href="https://github.com/kaifuyang/Gray-Pixel" target="_blank">Codes</a>]</li>
<li>SB Gao, <b>KF Yang</b>, CY Li, YJ Li. Color Constancy Using Double-Opponency. <b>IEEE TPAMI</b>, 2015.</li>
<li>SB Gao, <b>KF Yang</b>, CY Li, YJ Li. A Color Constancy Model with Double-Opponency Mechanisms. <b>ICCV</b>, 2013.</li>
</font>
</p> </td>
</tr>


<!--Attention-->
<tr>
<td><img class="proj_thumb" src="./pics/VisAtt.png" alt="" height="120px"/>&nbsp;</td>
<td>
<p class="pub_title">Guided Attention and Saliency Detection</p>
<font size="2.5">
<li>P Peng, <b>KF Yang*</b>, SQ Liang, YJ Li. Contour-guided Saliency Detection with Long-range Interactions. <b>Neurocomputing</b>, 2022. [<a class="p" href="https://github.com/PengPanda/LRSP" target="_blank">Codes</a>]</li>
<li>DH He, <b>KF Yang*</b>, XM Wan, F Xiao, HM Yan, YJ Li. A new representation of scene layout improves saliency detection in traffic scenes. <b>Expert Syst. Appl.</b>,2022.</li>
<li>P Peng, <b>KF Yang</b>, FY Luo, YJ Li. Saliency Detection Inspired by Topological Perception Theory. <b>IJCV</b>, 2021. [<a class="p" href="https://github.com/PengPanda/TopologicalSaliency" target="_blank">Codes</a>]</li>
<li><b>KF Yang</b>, H Li, CY Li, YJ Li. A Unified Framework for Salient Structure Detection by Contour-Guided Visual Search. <b>IEEE TIP</b>, 2016. [<a class="p" href="https://github.com/kaifuyang/Guided-Attention" target="_blank">Codes</a>]</li>
<LI>T Deng, <b>KF Yang</b>, YJ Li, HM Yan. Where Does the Driver Look? Top-Down-Based Saliency Detection in a Traffic Driving Environment. <b>IEEE TITS</b>, 2016.</li>
</font>
</p> </td>
</tr>
	
	
<!-- CRF Model-->
<tr>
<td><img class="proj_thumb" src="./pics/CRF.png" alt="" height="120px"/>&nbsp;</td>
<td>
<p class="pub_title">Receptive Field Models and Contour Detection </p>
<font size="2.5">
<li><b>KF Yang</b>, SB Gao, CF Guo, CY Li, YJ Li. Boundary Detection Using Double-Opponency and Spatial Sparseness Constraint. <b>IEEE TIP</b>, 2015. [<a class="p" href="https://github.com/kaifuyang/Receptive-Field-Models" target="_blank">Codes</a>]</li>
<li><b>KF Yang</b>, CY Li, YJ Li. Multifeature-based Surround Inhibition Improves Contour Detection in Natural Images. <b>IEEE TIP</b>, 2014. [<a class="p" href="https://github.com/kaifuyang/Receptive-Field-Models" target="_blank">Codes</a>]</li>
<li><b>KF Yang</b>, SB Gao, CY Li, YJ Li. Efficient Color Boundary Detection with Color-opponent Mechanisms. <b>CVPR</b>, 2013. [<a class="p" href="https://github.com/kaifuyang/Receptive-Field-Models" target="_blank">Codes</a>]</li>
</font>
</p> </td>
</tr>
	
</table> 
<hr>

<h3>(2) Artificial Intelligence in Medicine</h3>
<!--To develop advanced methods for medical image analysis and disease diagnosis. -->
<hr>

<table class="imgtable">

<!--Ophthalmic--> 
<tr>
<td><img class="proj_thumb" src="./pics/OphImg.png" alt="" height="150px"/>&nbsp;</td>
<td>
<p class="pub_title">Ophthalmic Image Analysis</p>
<font size="2.5">
<li>Y Tan, WD Shen,..., <b>KF Yang*</b>, YJ Li*. Retinal Layer Segmentation in OCT images with Boundary Regression and Feature Polarization. <b>IEEE TMI</b>, 2023.</li>
<li>Y Tan, SX Zhao, <b>KF Yang*</b>, YJ Li*. A lightweight network guided with differential matched filtering for retinal vessel segmentation. <b>Comput. Biol. Med.</b>, 2023.</li>
<li>X Wei, <b>KF Yang</b>, D Bzdok, YJ Li. Orientation and context entangled network for retinal vessel segmentation. <b>Expert Syst. Appl.</b> 2023.</li>
<li>Y Tan, <b>KF Yang*</b>, SX Zhao, YJ Li. Retinal Vessel Segmentation with Skeletal Prior and Contrastive Loss. <b>IEEE TMI</b>, 2022. [<a class="p" href="https://github.com/tyb311/SkelCon" target="_blank">Codes</a>]</li>
<li>J Wang, YJ Li, <b>KF Yang*</b>. Retinal fundus Image Enhancement with Image Decomposition and Visual Adaptation. <b>Comput. Biol. Med.</b>, 2021.</li>
</font>
</p> </td>
</tr>
	
<!--Others--> 
<tr>
<td><img class="proj_thumb" src="./pics/Others.png" alt="" height="120px"/>&nbsp;</td>
<td>
<p class="pub_title"> Other Topics</p>
<font size="2.5">
<li>WW Yu, J Jiang, <b>KF Yang</b>, HM Yan, YJ Li. LGSNet: A Two-Stream Network for Micro-and Macro-Expression Spotting With Background Modeling. <b>IEEE TAFFC</b>, 2023.</li>
<li>SX Zhao, Y Chen, <b>KF Yang</b>, Y Luo, BY Ma, YJ Li. A Local and Global Feature Disentangled Network: Toward Classification of Benign-malignant Thyroid Nodules from Ultrasound Image. <b>IEEE TMI</b>, 2022.</li>
</font>
</p> </td>
</tr>
	
</table> 
<hr>

<!--<h2>Professional Activities</h2>--> 
<!--IEEE Member --> 
<!--AE for IET Image Processing--> 
<!--Reviewer for IJCV, IEEE T-IP, IEEE T-ITS, etc.--> 
	
<div id="footer">
<div id="footer-text">

</div>
</div>
</body>
</html>
